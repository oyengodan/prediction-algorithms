{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Naive Bayes is a supervised learning classifier that can be trained to predict the label of future values (e.g, health outcome, spam detection, credit risk, etc.). The Naive Bayes equation is based on conditional probability whereby predictions are made from dependent events:\n",
    "\n",
    "$$P(A \\cap B)=P(A | B) P(B)=P(B | A)P(A)$$\n",
    "\n",
    "Solving one side of the equation, we get the Naive Bayes equation:\n",
    "\n",
    "$$P(A|B)=\\dfrac{P(B | A) P(A)}{P(B)}$$\n",
    "\n",
    "To avoid confusion, I will use the following variables:\n",
    "\n",
    "- *X*: The x-variables in the dataset organized in a matrix, where every row is a unique observation and every column a unique characteristic/feature (synonyms: predictors, explanatory variable, features, input variables, conditions, independent variable)\n",
    "- *y*: The y-variables in the dataset organized in a vector (synonyms: response variable, outcome/output variable, label, dependent variable)\n",
    "\n",
    "## Assumptions\n",
    "The following assumptions hold for Naive Bayes:\n",
    "\n",
    "- *X* features/columns are independent of one another\n",
    "\n",
    "- Similar x-values will be observed in future predictions\n",
    "\n",
    "- Smoothing (e.g., Laplace) is necessary when a category to be predicted equals the minimum (0) or maximum (1) probability.\n",
    "\n",
    "- Some programs ([IBM](https://www.ibm.com/support/knowledgecenter/en/SS3RA7_15.0.0/com.ibm.spss.modeler.help/dbmining_oracle_data.htm), [Microsoft](https://docs.microsoft.com/en-us/sql/analysis-services/data-mining/microsoft-naive-bayes-algorithm)) require binning of all continous values prior to using Naive Bayes. \n",
    "\n",
    "There are different Naive Bayes equations for different types of data:\n",
    "\n",
    "1. **Multinomial:** Categorical or continous data that can be described by counts\n",
    "\n",
    "2. **Bernoulli:** Binary data\n",
    "\n",
    "3. **Gaussian:** Normally distributed data\n",
    "\n",
    "If the data does not fit any of the methods above (e.g., contains continous and categorical data) then the continous variables can be binned (e.g., by percentile) prior to splitting the data into training and testing. This effectively makes all the data categorical and prepares it for Bernoulli Naive Bayes.  \n",
    "\n",
    "\n",
    "## Non-Code Example\n",
    "\n",
    "15 e-mail subject lines are recorded and labeled as spam depending on the content of the e-mail. Given the frequency table below, what is the likelihood of an e-mail being spam if it contains special characters in the subject line? Use Naive Bayes to calculate your prediction.\n",
    "\n",
    "| Condition | No (spam)   |  Yes (spam)   |\n",
    "|:------|------|------|\n",
    "|   > 10 words  | 2 |  1 |\n",
    "|   Special character(s)  | 5 |  4 |\n",
    "|   Capital letter(s)  | 0 |  3 |\n",
    "|   All observations  | 7 |  8 |\n",
    "\n",
    "$$P(Yes \\space | \\space Special \\space characters)=\\dfrac{P(Special \\space characters \\space |  \\space Yes) \\times P(Yes)}{P(Special \\space characters)}$$\n",
    "\n",
    "Plugin values from frequency table:\n",
    "\n",
    "$$P(Yes| \\space Special \\space characters)=\\dfrac{\\dfrac{4}{8}\\times\\dfrac{8}{15}}{\\dfrac{9}{15}}$$\n",
    "\n",
    "Calculate the solution:\n",
    "\n",
    "$$P(Yes| \\space Special \\space characters)=0.44$$\n",
    "\n",
    "It is more likely that an e-mail with special characters in subject line will **not** be spam (1-0.444..=0.555..). The likelihood that the e-mail will be spam if it contains special characters is approximately 0.44.\n",
    "\n",
    "Let's see the code equivalent (0=no, 1=yes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The likelihood of not being spam is approx: 0.556\n",
      "A new subject line with special characters is predicted to be: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "X_example = [[1,0,0],[1,0,0],\n",
    "             [1,0,0],\n",
    "             [0,1,0],[0,1,0],[0,1,0],[0,1,0],[0,1,0],\n",
    "             [0,1,0],[0,1,0],[0,1,0],[0,1,0],\n",
    "             [0,0,1],[0,0,1],[0,0,1]]\n",
    "y_example = [0,0,1,0,0,0,0,0,1,1,1,1,1,1,1]\n",
    "model_example = BernoulliNB(fit_prior=True)\n",
    "model_example.fit(X_example, y_example)\n",
    "print(\"The likelihood of not being spam is approx: %.3f\" % model_example.score(X_example[3:12],y_example[3:12]))\n",
    "print(\"A new subject line with special characters is predicted to be: %d\" % model_example.predict([[0,1,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Spam E-mails using Naive Bayes and Python\n",
    "Now let's use a (larger) publically available dataset from the University of California Irvine to detect spam e-mails based on the content of the email rather than special characters in the subject line. This setup requires Python 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import scipy.stats as stats\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21  0.28  0.5  ...,  0.    0.    0.  ]\n",
      " [ 0.06  0.    0.71 ...,  0.06  0.    0.  ]\n",
      " [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      " ..., \n",
      " [ 0.3   0.    0.3  ...,  1.2   0.    0.  ]\n",
      " [ 0.96  0.    0.   ...,  0.32  0.    0.  ]\n",
      " [ 0.    0.    0.65 ...,  0.65  0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "raw_data = urlopen(url) \n",
    "dataset = np.loadtxt(raw_data, delimiter=\",\")\n",
    "\n",
    "X = dataset [1:,0:48]\n",
    "print(X)\n",
    "y = dataset [1:, -1]\n",
    "\n",
    "x_simulation = dataset [0,0:48]\n",
    "y_simulation = dataset [0, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the dataset contains 4,601 rows/unique e-mails from one user. Each column ($n_{columns}$=48) represents the frequency of a searched word divided by the total words in that e-mail. The counts of all the words in the dataset are taken out of context of other words (hence the NLP association of 'bag of words' with Naive Bayes). \n",
    "\n",
    "The first entry in the data is 0, indicating that the word \"make\" occured 0 times in the first e-mail. A list of all 48 words can be found at [University of California Irvine Spambase Archives](https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names). If we look at the *y* dataset, we find that the first e-mail was indicated as 0, or not spam.\n",
    "\n",
    "Since this dataset describes different 'documents' as e-mails and counts of words, we can use all types of Naive Bayes methods. With some tweaks of course! \n",
    "\n",
    "This setup differs from the non-code example above where the column values are the frequency of spam/no spam labels. The [Scikit-learn Naive Bayes](http://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes) library will take care of counting the frequencies and organizing the data for us depending on the Naive Bayes equation used (e.g., Bernoulli, multinomial, or Gaussian).\n",
    "\n",
    "**Note: ** Since we don't have extra data, we'll reserve the first row of the data for 'simulation'. We'll use *x_simulation* and *y_simulation* in our last step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Naive Bayes Accuracy\n",
    "\n",
    "In the non-code example we simply generated a prediction with the 15 observations available without evaluating the likelihood of the prediction's accuracy. Now we'll take advantage of the fact that we have more observations available ($n_{rows}$=4,601) to generate predictions on a subset of the data and calculate the rate of prediction accuracy. Using this method, we can choose the best Naive Bayes equation and maintain a general idea of the equation's accuracy.\n",
    "\n",
    "**Note: ** You may choose to not test and compare the accuracy of every Naive Bayes equation and instead, directly use the equation that can be used with your non-altered data. However, as mentioned above, the calculation of an equation's accuracy based on a training and testing dataset is still valuable. Some methods may require an altering of the data: Bernoulli Naive Bayes may require a reformatting to binary form, Gaussian Naive Bayes may require a log transformation to be normally distributed. Each alteration of the data limits the generalizability and inference of the data and should therefore be done with caution.\n",
    "\n",
    "Cross-validation can also be used to obtain more robust accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes\n",
    "\n",
    "First we adapt the data to be used with Bernoulli Naive Bayes by assigning all non-zero values as 1 (using binarize=True). Then we compare the prediction results of y_pred to y_expect to generate the number or correctly predicted values divided by all predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1.0, binarize=0.1, class_prior=None, fit_prior=True)\n",
      "Accuracy is: 0.89\n",
      "Precision is: 0.88\n",
      "Recall/sensitivity is: 0.82\n",
      "[[857  64]\n",
      " [109 488]]\n"
     ]
    }
   ],
   "source": [
    "BernNB = BernoulliNB(binarize=0.1)\n",
    "BernNB.fit(X_train, y_train)\n",
    "print(BernNB)\n",
    "\n",
    "y_expect = y_test\n",
    "y_pred = BernNB.predict(X_test)\n",
    "accuracy_score(y_expect, y_pred)\n",
    "print(\"Accuracy is: %.2f\" % accuracy_score(y_expect, y_pred))\n",
    "print(\"Precision is: %.2f\" % precision_score(y_expect, y_pred))\n",
    "print(\"Recall/sensitivity is: %.2f\" % recall_score(y_expect, y_pred))\n",
    "print(confusion_matrix(y_expect, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes \n",
    "\n",
    "Since the data we have is continous, we can use the multinomial equation directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Accuracy is: 0.86\n",
      "Precision is: 0.77\n",
      "Recall/sensitivity is: 0.94\n",
      "[[751 170]\n",
      " [ 36 561]]\n"
     ]
    }
   ],
   "source": [
    "MultiNB = MultinomialNB()\n",
    "MultiNB.fit(X_train, y_train)\n",
    "print(MultiNB)\n",
    "\n",
    "y_pred=MultiNB.predict(X_test)\n",
    "print(\"Accuracy is: %.2f\" % accuracy_score(y_expect, y_pred))\n",
    "print(\"Precision is: %.2f\" % precision_score(y_expect, y_pred))\n",
    "print(\"Recall/sensitivity is: %.2f\" % recall_score(y_expect, y_pred))\n",
    "print(confusion_matrix(y_expect, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes\n",
    "\n",
    "Gaussian Naive Bayes assumes that we have a normal distribution, so let's first test for a normal distribution in each of the columns/words. We will use a $p \\space value<0.05$ as our threshold for distinguising values that are non-normal. If you print the result of the normal test, you will see that all columns are $<0.05$, allowing us to directly use the Gaussian Naive Bayes equation without any transformation of the data.\n",
    "\n",
    "**Note: ** Here we chose 0.05 as the significance level for the normality test. To choose the right significance level for your data, find the 'standard' levels used in your research domain. I look for this information in related studies/full papers within blind peer-reviewed (non open-souce) journal articles or conference proceedings. Typically 0.01 is used for 'high risk' research (e.g., health-related studies) and 0.05 for low risk research. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "Accuracy is: 0.80\n",
      "Precision is: 0.67\n",
      "Recall/sensitivity is: 0.95\n",
      "[[642 279]\n",
      " [ 29 568]]\n"
     ]
    }
   ],
   "source": [
    "stats.normaltest(X_train)\n",
    "\n",
    "GausNB = GaussianNB()\n",
    "GausNB.fit(X_train, y_train)\n",
    "print(GausNB)\n",
    "\n",
    "y_pred = GausNB.predict(X_test)\n",
    "print(\"Accuracy is: %.2f\" % accuracy_score(y_expect, y_pred))\n",
    "print(\"Precision is: %.2f\" % precision_score(y_expect, y_pred))\n",
    "print(\"Recall/sensitivity is: %.2f\" % recall_score(y_expect, y_pred))\n",
    "print(confusion_matrix(y_expect, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing Naive Bayes Models\n",
    "\n",
    "### Accuracy\n",
    "Based on the tests above, the two best equations are Bernoulli Naive Bayes (altered data, $accuracy=0.89$) and Multinomial Naive Bayes (non-altered data, $accuracy=0.86$). \n",
    "\n",
    "### Recall & Precision\n",
    "Although Multinomial Naive Bayes had a higher recall (0.94) than Bernoulli Naive Bayes (0.82), the confusion matricies show that Multinomial Naive Bayes would have also had more occurances (n=170) of placing your e-mails in the spam folder (precision=0.77). \n",
    "\n",
    "### F1-Score\n",
    "Bernoulli Naive Bayes more often correctly identified both spam/not spam labels, and had a more balanced precision and recall (Bernoulli F1-score=0.85, Multinomial F1-score=0.84). On the instances where Bernoulli mislabled e-mails, it had more occurances (n=109) of placing a spam e-mail in your inbox.\n",
    "\n",
    "## Generating predictions with Bernoulli Naive Bayes\n",
    "We will use Bernoulli Naive Bayes trained above (BernNB) as our equation and the *x_simulation* variable we previously reserved to simulate a new entry to be predicted upon. \n",
    "\n",
    "**Note: **If we were to run our trained Naive Bayes with our test data, we would get a high prediction accuracy, as this was the data we originally used to select Bernoulli over Multinomial. It would not provide us any additional insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.]\n"
     ]
    }
   ],
   "source": [
    "new_entry = x_simulation.reshape(1, -1)\n",
    "y_pred = BernNB.predict(new_entry)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A prediction of 1 indicates that the e-mail is spam. We can assume that this is likely to be true as prior testing indicated that the Bernoulli Naive Bayes model had an accuracy of 0.89.\n",
    "\n",
    "If we look at the true value we see that our prediction was indeed correct! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(y_simulation)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
